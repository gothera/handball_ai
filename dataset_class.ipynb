{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb9486e",
   "metadata": {
    "time_run": "2026-02-03T19:49:47.416410+00:00"
   },
   "source": [
    "We will now define the dataset class for our image dataset consisting of keypoint annotations inside images. When computing heatmaps(one for each keypoint present in an image), we will also make heatmaps for lines present in the annotation jsons for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d056e",
   "metadata": {
    "time_run": "2026-02-06T21:43:20.720552+00:00"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from typing import List, Tuple, Callable, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cf3d3",
   "metadata": {
    "time_run": "2026-02-06T21:43:20.924104+00:00"
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig\n",
    "cfg = OmegaConf.load('train_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1133df",
   "metadata": {
    "time_run": "2026-02-06T21:43:21.210765+00:00"
   },
   "outputs": [],
   "source": [
    "class HRNetDataset(Dataset):\n",
    "    def __init__(self, dataset_folder: str, transform: Optional[Callable] = None, num_keypoints: int = 30, img_size: Tuple[int, int] = (960, 540), margin: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dataset_folder,self.num_keypoints,self.transform,self.img_size,self.margin = dataset_folder,num_keypoints,transform,img_size,margin\n",
    "        self.img_paths = [p for p in Path(dataset_folder).glob('*.jpg') if p.with_suffix('.json').exists()]        \n",
    "    \n",
    "    def __len__(self): return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        sample = dict(image=image)\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "        annot_path = img_path.with_suffix('.json')\n",
    "        keypoints,mask,lines = self._annot2keypoints(annot_path)\n",
    "        sample.update(dict(keypoints=keypoints, img_idx=idx, mask=mask, img_name=img_path.name, lines=lines))\n",
    "        return sample\n",
    "    \n",
    "    def _annot2keypoints(self, annot_path):\n",
    "        with open(annot_path) as f: data = json.loads(f.read())\n",
    "        kpts_dict,lines = {},[]\n",
    "        for shape in data['shapes']:\n",
    "            if shape['shape_type'] == 'point': kpts_dict[int(shape['label'])] = shape['points'][0]\n",
    "            elif shape['shape_type'] == 'linestrip': lines.append(dict(label=shape['label'], points=shape['points']))\n",
    "        keypoints = np.ones(self.num_keypoints * 3, dtype=np.float32) * -1\n",
    "        mask = np.ones(self.num_keypoints, dtype=int)\n",
    "        for i in range(self.num_keypoints):\n",
    "            if i in kpts_dict:\n",
    "                keypoints[i*3:i*3+2] = kpts_dict[i]\n",
    "                keypoints[i*3+2] = 1\n",
    "                mask[i] = 0\n",
    "            else: keypoints[i*3+2] = 0\n",
    "        return keypoints,mask,lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117d8ba",
   "metadata": {
    "time_run": "2026-02-06T21:43:22.019792+00:00"
   },
   "outputs": [],
   "source": [
    "def create_heatmaps(keypoints: torch.Tensor, sigma: float,\n",
    "                    pred_size: Tuple[int, int] = (540, 960)) -> torch.Tensor:\n",
    "    \"\"\"Create Gaussian distributions heatmaps for keypoints.\n",
    "\n",
    "    Each heatmap is drawn on an individual channel.\n",
    "\n",
    "    Args:\n",
    "        keypoints (torch.Tensor): A batch (B) of N points, each point is (x, y).\n",
    "            Expected shape: (B, N, 2).\n",
    "        sigma (float): Standard deviation.\n",
    "        pred_size (Tuple[int, int]): Size of the 2D Gaussian distribution canvas\n",
    "            (H, W). Defaults to (68, 120).\n",
    "\n",
    "    Returns:\n",
    "        (torch.Tensor): Resulted Gaussian heatmaps: (B, N, H, W).\n",
    "\n",
    "    \"\"\"\n",
    "    h, w = pred_size\n",
    "    device = keypoints.device\n",
    "    x = keypoints[:, :, 0]\n",
    "    y = keypoints[:, :, 1]\n",
    "\n",
    "    x_range = torch.arange(0, w, device=device, dtype=torch.float32)\n",
    "    y_range = torch.arange(0, h, device=device, dtype=torch.float32)\n",
    "    gauss_x: torch.Tensor = gaussian(x_range, x, sigma)\n",
    "    gauss_y: torch.Tensor = gaussian(y_range, y, sigma)\n",
    "    heatmaps = torch.einsum(\"BNW, BNH -> BNHW\", gauss_x, gauss_y)\n",
    "\n",
    "    visible_points = torch.any(keypoints == 1, dim=-1, keepdim=True)\n",
    "    zero = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
    "    heatmaps = torch.where(visible_points.unsqueeze(-1), heatmaps, zero)\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84ddc8",
   "metadata": {
    "time_run": "2026-02-06T21:43:22.686880+00:00"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset, default_collate\n",
    "\n",
    "def custom_collate(batch):\n",
    "    default_collated = default_collate([{k: v for k, v in sample.items()\n",
    "                                         if k in collate_objs}\n",
    "                                        for sample in batch])\n",
    "    custom_collated = {'img_name': [sample['img_name'] for sample in batch]}\n",
    "\n",
    "    return {**default_collated, **custom_collated}\n",
    "\n",
    "def get_loader(dataset_paths: List[str], data_params: DictConfig,\n",
    "\n",
    "               transform: Optional[Callable] = None, shuffle: bool = True)\\\n",
    "        -> DataLoader:\n",
    "    datasets = []\n",
    "    for dataset_path in dataset_paths:\n",
    "        datasets.append(HRNetDataset(dataset_path, transform=transform,\n",
    "                                     num_keypoints=data_params.num_keypoints,\n",
    "                                     margin=data_params.margin))\n",
    "    dataset = ConcatDataset(datasets)\n",
    "    factor = 1 if shuffle else 2\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=data_params.batch_size * factor,\n",
    "        num_workers=data_params.num_workers,\n",
    "        pin_memory=data_params.pin_memory,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=custom_collate)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06ef96",
   "metadata": {
    "time_run": "2026-02-05T22:02:47.164956+00:00"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m",
      "\u001b[32m      1\u001b[39m dataset = HRNetDataset(dataset_folder=\u001b[33m'\u001b[39m\u001b[33m./clean_keypoints_dataset/\u001b[39m\u001b[33m'\u001b[39m)",
      "\u001b[32m      2\u001b[39m sample = dataset[\u001b[32m0\u001b[39m]",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_loader = \u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m",
      "\u001b[32m      4\u001b[39m dl = \u001b[38;5;28miter\u001b[39m(train_loader)",
      "\u001b[32m      6\u001b[39m batch = \u001b[38;5;28mnext\u001b[39m(dl)",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mget_loader\u001b[39m\u001b[34m(dataset_paths, data_params, transform, shuffle)\u001b[39m",
      "\u001b[32m     20\u001b[39m dataset = ConcatDataset(datasets)",
      "\u001b[32m     21\u001b[39m factor = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m2\u001b[39m",
      "\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m",
      "\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_collate\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loader",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:394\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m",
      "\u001b[32m    392\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m",
      "\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:",
      "\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m",
      "\u001b[32m    395\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[32m    396\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/data/sampler.py:149\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m",
      "\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(",
      "\u001b[32m    145\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m",
      "\u001b[32m    146\u001b[39m     )",
      "\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:",
      "\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(",
      "\u001b[32m    150\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m",
      "\u001b[32m    151\u001b[39m     )",
      "",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "dataset = HRNetDataset(dataset_folder='./clean_keypoints_dataset/')\n",
    "sample = dataset[0]\n",
    "train_loader = get_loader(cfg.data.train, cfg.data_params, None, True)\n",
    "dl = iter(train_loader)\n",
    "\n",
    "batch = next(dl)\n",
    "img, keypoints, mask = batch['image'][0], batch['keypoints'][0].reshape(-1, cfg.data_params.num_keypoints, 3), batch['mask'][0]\n",
    "print(img.shape, keypoints.shape, mask.shape)\n",
    "\n",
    "for batch in dl:\n",
    "    for idx in range(cfg.data_params.batch_size):\n",
    "        img, keypoints, mask = batch['image'][idx], batch['keypoints'][idx].reshape(-1, cfg.data_params.num_keypoints, 3), batch['mask'][idx]\n",
    "        # print(img.shape, keypoints.shape, mask.shape)\n",
    "        heatmaps = create_heatmaps(keypoints, 1.0)\n",
    "        heatmaps = torch.cat(\n",
    "                [heatmaps, (1.0 - torch.max(heatmaps, dim=1, keepdim=True)[0])], 1)\n",
    "        maps = torch.sum(heatmaps[0][:-1], 0)\n",
    "        # plot_heatmap(maps)\n",
    "\n",
    "        plot_img_keypoints(img.detach().cpu().numpy(), maps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860284a",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2026-02-05T19:10:35.060923+00:00"
   },
   "source": [
    "6 self.img_paths = filter(sorted([p for p in Path(dataset_folder).glob('*.jpg')]), lambda x: os.path.exists(x.replace('.jpg', '.json')))\n",
    "\n",
    "TypeError: 'function' object is not iterable\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The issue is that `filter` returns a filter object, not a list, and the arguments are in the wrong order. Here's the fix:\n",
    "\n",
    "```python\n",
    "class HRNetDataset(Dataset):\n",
    "    def __init__(self, dataset_folder: str, transform: Optional[Callable] = None, num_keypoints: int = 30, img_size: Tuple[int, int] = (960, 540), margin: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dataset_folder,self.num_keypoints,self.transform,self.img_size,self.margin = dataset_folder,num_keypoints,transform,img_size,margin\n",
    "        all_imgs = sorted([p for p in Path(dataset_folder).glob('*.jpg')])\n",
    "        self.img_paths = [p for p in all_imgs if p.with_suffix('.json').exists()]\n",
    "        \n",
    "    def __len__(self): return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        sample = dict(image=image)\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "        annot_path = img_path.with_suffix('.json')\n",
    "        keypoints,mask,lines = self._annot2keypoints(annot_path)\n",
    "        sample.update(dict(keypoints=keypoints, img_idx=idx, mask=mask, img_name=img_path.name, lines=lines))\n",
    "        return sample\n",
    "    \n",
    "    def _annot2keypoints(self, annot_path):\n",
    "        with open(annot_path) as f: data = json.loads(f.read())\n",
    "        kpts_dict,lines = {},[]\n",
    "        for shape in data['shapes']:\n",
    "            if shape['shape_type'] == 'point': kpts_dict[int(shape['label'])] = shape['points'][0]\n",
    "            elif shape['shape_type'] == 'linestrip': lines.append(dict(label=shape['label'], points=shape['points']))\n",
    "        keypoints = np.ones(self.num_keypoints * 3, dtype=np.float32) * -1\n",
    "        mask = np.ones(self.num_keypoints, dtype=int)\n",
    "        for i in range(self.num_keypoints):\n",
    "            if i in kpts_dict:\n",
    "                keypoints[i*3:i*3+2] = kpts_dict[i]\n",
    "                keypoints[i*3+2] = 1\n",
    "                mask[i] = 0\n",
    "            else: keypoints[i*3+2] = 0\n",
    "        return keypoints,mask,lines\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
